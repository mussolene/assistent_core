# Приёмочное тестирование

Чек-лист для проверки фич перед релизом. Выполнять после `docker compose up --build`.

## Подготовка

- [ ] `.env` при необходимости (OPENAI_BASE_URL для Docker)
- [ ] Ollama или LM Studio запущены на хосте (для проверки модели)

## Dashboard (http://localhost:8080)

- [ ] Открываются вкладки: Telegram, Модель, MCP, Мониторинг
- [ ] **Telegram:** сохранение токена и списка User ID; включение Pairing
- [ ] **Telegram:** кнопка «Проверить бота» возвращает OK и username
- [ ] **Модель:** сохранение URL, имени модели, опции LM Studio native
- [ ] **Модель:** кнопка «Проверить подключение» возвращает OK при доступной модели
- [ ] **MCP:** добавление сервера (имя, URL, аргументы JSON); отображение в списке; удаление
- [ ] **Мониторинг:** отображаются память Redis, подключения, число ключей

## Telegram бот

- [ ] Команды в меню: /start, /help, /reasoning
- [ ] **Pairing:** при включённом Pairing отправка /start боту добавляет пользователя в разрешённые
- [ ] Отправка сообщения боту — приходит ответ
- [ ] Ответ стримится в одном сообщении (текст дополняется)
- [ ] Показывается индикатор «печатает» при ответе
- [ ] В ответе нет сырого блока `<think>...</think>`
- [ ] При включённом LM Studio native в чат не попадают рассуждения (reasoning)

## Skills и память

- [ ] Запрос прочитать файл из workspace — корректый ответ (filesystem)
- [ ] Запрос выполнить разрешённую команду (shell whitelist)
- [ ] Запрос git status в репозитории (git)
- [ ] Несколько сообщений подряд — ассистент учитывает контекст (memory)

## Безопасность и лимиты

- [ ] Сообщение от пользователя не из whitelist (без Pairing) — игнорируется
- [ ] При превышении лимита запросов — сообщение о rate limit

## Запуск и стабильность

- [ ] `docker compose up --build` завершается без ошибок
- [ ] Все сервисы (redis, dashboard, assistant-core, telegram-adapter) в состоянии running
- [ ] Логи без критичных исключений при типичном сценарии (несколько запросов к боту)
